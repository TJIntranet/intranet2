#!/usr/bin/env python
import urllib2
from BeautifulSoup import BeautifulSoup
import string
import os
import sys

if not os.path.exists("config.ini"):
   sys.stderr.write("This program must be run from the root directory of iodine.\n")
   sys.exit(1)

links_file = open('templates/info/links.tpl', 'w')
proxy_file = open('www/proxy.pac', 'w')

page = urllib2.urlopen("http://academics.tjhsst.edu/library/database.htm")
soup = BeautifulSoup(page)
domains = []
for link in soup('a'):
   if link.span:
      href = link.get('href')
      if href == None or href.count("http") == 0 or href.count("fcps.edu") > 0 or href.count("tjhsst.edu") > 0 or href.count("co.fairfax.va.us") > 0:
         continue
      href = ' '.join(href.split())
      href = string.replace(href, '  ', ' ')
      href = string.replace(href, '  ', ' ')
      href = href.lower()
      contents = ""
      for i in range(0, len(link.contents)):
         contents += " " + ''.join(link.contents[i])
      contents = ' '.join(contents.split())
      contents = string.replace(contents, '&nbsp;', ' ')
      contents = string.replace(contents, '  ', ' ')
      contents = string.replace(contents, '  ', ' ')
      contents = string.replace(contents, '  ', ' ')
      if href.count(".eb.com") > 0:
         contents = "Britannica's Online Reference - " + contents
      links_file.write("<li><a href=\"" + href + "\">"+contents+"</a></li>\n")
      domains.append(href.split("/")[2])
   else:
      href = link.get('href')
      if href == None or href.count("http") == 0 or href.count("fcps.edu") > 0 or href.count("tjhsst.edu") > 0 or href.count("co.fairfax.va.us") > 0:
         continue
      href = ' '.join(href.split())
      href = string.replace(href, '  ', ' ')
      href = string.replace(href, '  ', ' ')
      href = href.lower()
      contents = ''.join(link.contents)
      contents = ' '.join(contents.split())
      contents = string.replace(contents, '&nbsp;', ' ')
      contents = string.replace(contents, '  ', ' ')
      contents = string.replace(contents, '  ', ' ')
      if href.count(".eb.com") > 0:
         contents = "Britannica's Online Reference - " + contents
      links_file.write("<li><a href=\"" + href + "\">"+contents+"</a></li>\n")
      domains.append(href.split("/")[2])

proxy_file.write("""/***********************************************************
** TJHSST Proxy Auto-Configuration Script                 **
** For use with TJHSST school databases                   **
** Use is restricted to TJHSST students and faculty ONLY. **
** All other use is prohibited.                           **
** Originally contributed by William Yang.                **
** Autogenerated version by Brandon Vargo.                **
************************************************************/

function FindProxyForURL(url, host)
{
\tif (\n""")
for i in range(0, len(domains)):
   proxy_file.write("\t\tdnsDomainIs(host, \"" + domains[i] + "\")")
   if i != len(domains) - 1:
      proxy_file.write(" ||\n")
   else:
      proxy_file.write("\n")
proxy_file.write("""
\t)
\t\t\treturn "PROXY local.border.tjhsst.edu:8080";
\t\telse
\t\t\treturn "DIRECT";
}
""")

links_file.close()
proxy_file.close()
